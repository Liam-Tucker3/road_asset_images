{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0171448e-13f5-4dc3-9927-43b8e5a409f2",
   "metadata": {},
   "source": [
    "## Reformatting LISA datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f29f67-b79b-4c71-9832-2f59125c46bf",
   "metadata": {},
   "source": [
    "The LISA datasets-- traffic lights and traffic signs-- are stored in a series of different folders. Within each folder is a csv file, where each row corresponds to one object. In order to train the YOLO model, I need three folders-- a train, validate, and test folder-- which each contain two folders: images and labels. For each image, I have a imageName.jpg file in the images folder-- the image itself-- and a imageName.txt file in the labels folder, with one row per object in that image.\n",
    "\n",
    "This script converts from the LISA format into the YOLO format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceb8743d-9ab0-407e-b7b4-fcf29af7a8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ab90d08-d8c0-4cba-941f-cf225a82f4c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_images/LISA_traffic_lights/dayTrain/dayClip1\n",
      "raw_images/LISA_traffic_lights/dayTrain/dayClip2\n",
      "raw_images/LISA_traffic_lights/dayTrain/dayClip3\n",
      "raw_images/LISA_traffic_lights/dayTrain/dayClip4\n",
      "raw_images/LISA_traffic_lights/dayTrain/dayClip5\n",
      "raw_images/LISA_traffic_lights/dayTrain/dayClip6\n",
      "raw_images/LISA_traffic_lights/dayTrain/dayClip7\n",
      "raw_images/LISA_traffic_lights/dayTrain/dayClip8\n",
      "raw_images/LISA_traffic_lights/dayTrain/dayClip9\n",
      "raw_images/LISA_traffic_lights/dayTrain/dayClip10\n",
      "raw_images/LISA_traffic_lights/dayTrain/dayClip11\n",
      "raw_images/LISA_traffic_lights/dayTrain/dayClip12\n",
      "raw_images/LISA_traffic_lights/dayTrain/dayClip13\n",
      "raw_images/LISA_traffic_lights/nightTrain/nightClip1\n",
      "raw_images/LISA_traffic_lights/nightTrain/nightClip2\n",
      "raw_images/LISA_traffic_lights/nightTrain/nightClip3\n",
      "raw_images/LISA_traffic_lights/nightTrain/nightClip4\n",
      "raw_images/LISA_traffic_lights/nightTrain/nightClip5\n"
     ]
    }
   ],
   "source": [
    "# Getting all training images\n",
    "lisa_relative_path = \"raw_images/LISA_traffic_lights\"\n",
    "day_folders = [f\"{lisa_relative_path}/dayTrain/dayClip{i}\" for i in range(1, 14)]\n",
    "night_folders = [f\"{lisa_relative_path}/nightTrain/nightClip{i}\" for i in range(1, 6)]\n",
    "folders = day_folders + night_folders\n",
    "\n",
    "# Creating two folder sets: one with labels and images for day, one for night\n",
    "save = True # Whether I save the images in the YOLO format\n",
    "dest_dir = \"YOLO_data/LISA_traffic_lights\"\n",
    "day_dir = os.path.join(dest_dir, \"day\")\n",
    "night_dir = os.path.join(dest_dir, \"night\")\n",
    "if not os.path.exists(dest_dir): os.mkdir(dest_dir)\n",
    "if not os.path.exists(day_dir): os.mkdir(day_dir)\n",
    "if not os.path.exists(night_dir): os.mkdir(night_dir)\n",
    "\n",
    "for this_dir in [day_dir, night_dir]:\n",
    "    img_dir = os.path.join(this_dir, 'images')\n",
    "    txt_dir = os.path.join(this_dir, 'labels')\n",
    "    if not os.path.exists(img_dir): os.mkdir(img_dir)\n",
    "    if not os.path.exists(txt_dir): os.mkdir(txt_dir)\n",
    "\n",
    "for f in folders: print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d31ea113-8619-4ded-a3c2-2f652434da54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 raw_images/LISA_traffic_lights/dayTrain/dayClip1\n",
      "1 raw_images/LISA_traffic_lights/dayTrain/dayClip2\n",
      "2 raw_images/LISA_traffic_lights/dayTrain/dayClip3\n",
      "3 raw_images/LISA_traffic_lights/dayTrain/dayClip4\n",
      "4 raw_images/LISA_traffic_lights/dayTrain/dayClip5\n",
      "5 raw_images/LISA_traffic_lights/dayTrain/dayClip6\n",
      "6 raw_images/LISA_traffic_lights/dayTrain/dayClip7\n",
      "7 raw_images/LISA_traffic_lights/dayTrain/dayClip8\n",
      "8 raw_images/LISA_traffic_lights/dayTrain/dayClip9\n",
      "9 raw_images/LISA_traffic_lights/dayTrain/dayClip10\n",
      "10 raw_images/LISA_traffic_lights/dayTrain/dayClip11\n",
      "11 raw_images/LISA_traffic_lights/dayTrain/dayClip12\n",
      "12 raw_images/LISA_traffic_lights/dayTrain/dayClip13\n",
      "13 raw_images/LISA_traffic_lights/nightTrain/nightClip1\n",
      "14 raw_images/LISA_traffic_lights/nightTrain/nightClip2\n",
      "15 raw_images/LISA_traffic_lights/nightTrain/nightClip3\n",
      "16 raw_images/LISA_traffic_lights/nightTrain/nightClip4\n",
      "17 raw_images/LISA_traffic_lights/nightTrain/nightClip5\n"
     ]
    }
   ],
   "source": [
    "# Copying images from into YOLO Folder\n",
    "\n",
    "# Determining list of unique labels\n",
    "unique_dict = {0: 'stop', 1: 'stopLeft', 2: 'go', 3: 'goLeft', 4: 'warning', 5: 'warningLeft'}\n",
    "lookup_dict = {}\n",
    "for key, value in unique_dict.items(): lookup_dict[value] = key\n",
    "first_lookup_dict = {}\n",
    "\n",
    "for x, f in enumerate(folders):\n",
    "    print(x, f)\n",
    "\n",
    "    # Loading the data frame for this folders' training sequence\n",
    "    csv_path = os.path.join(lisa_relative_path, f\"Annotations/Annotations/{f[31:]}/frameAnnotationsBOX.csv\")\n",
    "    col_names = ['file_name', 'label', 'xmin', 'ymin', 'xmax', 'ymax', 'origin', 'frame', 'origin2', 'frame2']\n",
    "    label_df = pd.read_csv(csv_path, sep=';', header=0, names=col_names)\n",
    "\n",
    "    # Cleaning up filenames\n",
    "    if \"day\" in f: label_df['file_name'] = 'frames/' + label_df['file_name'].str[12:]\n",
    "    else: label_df['file_name'] = 'frames/' + label_df['file_name'].str[14:]\n",
    "    # display(label_df.head())\n",
    "\n",
    "    # Determining list of unique files\n",
    "    unique_files = label_df['file_name'].unique()\n",
    "    n_unique_files = unique_files.shape[0]\n",
    "    all_indices = np.linspace(0, n_unique_files-1, n_unique_files-1)\n",
    "\n",
    "    # Compiling all data for .txt file for each image\n",
    "    for i, (img_path, txt_df) in enumerate(label_df.groupby('file_name')):\n",
    "        lines = list()\n",
    "        for row in txt_df.itertuples():\n",
    "            xcenter = int((row.xmin + row.xmax) / 2) / 1280\n",
    "            if xcenter >= 1: print(row.xmin, row.xmax, xcenter)\n",
    "            ycenter = int((row.ymin + row.ymax) / 2) / 960\n",
    "            xwidth = (row.xmax - row.xmin) / 1280\n",
    "            ywidth = (row.ymax - row.ymin) / 960\n",
    "            line = f\"{lookup_dict[row.label]} {xcenter} {ycenter} {xwidth} {ywidth}\"\n",
    "            lines.append(line)\n",
    "            if float(line.split(' ')[1]) > 1.0:\n",
    "                print(line)\n",
    "\n",
    "        # Determining if these files belong in the day or night folder\n",
    "        this_mode = \"night\"\n",
    "        if \"day\" in f: this_mode = \"day\"\n",
    "\n",
    "        # Getting file paths\n",
    "        old_img_path = f\"{lisa_relative_path}/{this_mode}Train/{this_mode}Train/{f.rsplit('/', 1)[1]}/{img_path}\"\n",
    "        new_img_path = f\"{dest_dir}/{this_mode}/images/{x:03d}_{i:04d}.jpg\"\n",
    "        new_txt_path = f\"{dest_dir}/{this_mode}/labels/{x:03d}_{i:04d}.txt\"\n",
    "\n",
    "        first_lookup_dict[new_txt_path] = old_img_path\n",
    "\n",
    "        # Saving files to new YOLO location\n",
    "        if save:\n",
    "            shutil.copy(old_img_path, new_img_path)\n",
    "            with open(new_txt_path, 'w') as file:\n",
    "                for line in lines:\n",
    "                    file.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883ac51e-d61f-4e66-97b2-d97e12ba8145",
   "metadata": {},
   "source": [
    "The next step is to create more manageable, usable datasets from this large dataset. To start, I will make two datasets: One will have 2,000 images-- 60% training, 20% validation, and 20% testing. Each component will be 50% day photos, 50% night photos. The other dataset will have the same ratios but only 20 total images, taken from the first dataset. This second dataset will be used only for proof of concept runs-- i.e. I'll use it to quickly train a model to establish that all parts of a workflow work correctly, but the results of this model will never matter.\n",
    "\n",
    "Note that I also need to, for every dataset, adjust to the number of classes in the output. Basically, once I grab the X images for a dataset and copy them in, I need to detremine how many different classes of objects are in the datasets, adjust the classes listed in my .txt files, and create a corresponding .yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eee9321a-7a94-48b1-b288-89a5e0415b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates three folders called 'test', 'train', and 'valid'\n",
    "# Each with a \"images\" and \"label\" folder inside of them\n",
    "# Inside of this_dir\n",
    "def create_dataset_skeleton(this_dir):\n",
    "    # Creating main dataset folder\n",
    "    if not os.path.exists(this_dir): os.mkdir(this_dir)\n",
    "\n",
    "    # Creating test/train/valid folders\n",
    "    test_dir = os.path.join(this_dir, 'test')\n",
    "    train_dir = os.path.join(this_dir, 'train')\n",
    "    valid_dir = os.path.join(this_dir, 'valid')\n",
    "    if not os.path.exists(test_dir): os.mkdir(test_dir)\n",
    "    if not os.path.exists(train_dir): os.mkdir(train_dir)\n",
    "    if not os.path.exists(valid_dir): os.mkdir(valid_dir)\n",
    "\n",
    "    # Create images/labels folders\n",
    "    for next_dir in [\"test\", \"train\", \"valid\"]:\n",
    "        img_dir = os.path.join(this_dir, next_dir, 'images')\n",
    "        txt_dir = os.path.join(this_dir, next_dir, 'labels')\n",
    "        if not os.path.exists(img_dir): os.mkdir(img_dir)\n",
    "        if not os.path.exists(txt_dir): os.mkdir(txt_dir)\n",
    "\n",
    "# Taken from https://github.com/ncallahanml/potential_vehicle_projects/blob/main/Examples/YOLOv8Train%26Deployment.ipynb\n",
    "# this io could be handled with PyYAML\n",
    "def write_yaml_config(class_dict, save_path, primary_path=None, train_path=\"train/\", test_path=\"test/\", valid_path=\"valid/\"):\n",
    "    yaml_content = f\"\"\"\n",
    "\n",
    "path: {primary_path}  # dataset root dir\n",
    "train: {train_path}  # train images (relative to 'path')\n",
    "val: {valid_path}  # val images (relative to 'path')\n",
    "test: {test_path}\n",
    "\n",
    "names:\"\"\"\n",
    "    for i in sorted(class_dict.keys()):\n",
    "        yaml_content += f\"\\n  {i}: {class_dict[i]}\"\n",
    "        \n",
    "    assert save_path.endswith('.yaml'), 'End file with .yaml extension'\n",
    "    with open(save_path, 'w') as file:\n",
    "        file.write(yaml_content)\n",
    "    return\n",
    "\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4c9e941-d962-4a9a-8fa4-1f52a5ee1c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO_data/LISA_traffic_lights\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import random\n",
    "\n",
    "\"\"\" Creating Dataset\"\"\"\n",
    "# Hardcoding certain parameters\n",
    "dest_dir1 = \"YOLO_data/DatasetMixed_2000\"\n",
    "dataset_size = 2000 # Total number of images in the dataset\n",
    "\n",
    "day_proportion, night_proportion = 0.5, 0.5 # Must add to 1\n",
    "train_proportion, val_proportion, test_proportion = 0.6, 0.2, 0.2 # Must add to 1\n",
    "\n",
    "# Creating Framework for datasets\n",
    "create_dataset_skeleton(dest_dir1)\n",
    "\n",
    "# Getting list of image filenames\n",
    "day_filenames = glob.glob(f\"{dest_dir}/day/images/*\")\n",
    "print(dest_dir)\n",
    "night_filenames = glob.glob(f\"{dest_dir}/night/images/*\")\n",
    "\n",
    "# Shuffling list of filenames (to randomly select files to use)\n",
    "random.shuffle(day_filenames)\n",
    "random.shuffle(night_filenames)\n",
    "\n",
    "# Determining which classes appear in the dataset\n",
    "unique_dict = {0: 'stop', 1: 'stopLeft', 2: 'go', 3: 'goLeft', 4: 'warning', 5: 'warningLeft'} # Hardcoded; all classes in big dataset\n",
    "this_dataset_classes = set()\n",
    "\n",
    "# Confirming there are enough files here to use\n",
    "assert len(day_filenames) >= dataset_size * day_proportion\n",
    "assert len(night_filenames) >= dataset_size * night_proportion\n",
    "\n",
    "# Adding each object's class\n",
    "for i in range(int(dataset_size * day_proportion)):\n",
    "    old_txt_path = f\"{day_filenames[i][:-20]}/labels/{day_filenames[i][-12:-4]}.txt\"\n",
    "    # print(old_txt_path)\n",
    "    with open(old_txt_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Split the line by the first space and take the first part\n",
    "            this_class = int(line.split(' ')[0])\n",
    "            # print(line.split(' ')[0], line.split(' ')[1])\n",
    "            this_dataset_classes.add(this_class)\n",
    "\n",
    "for i in range(int(dataset_size * night_proportion)):\n",
    "    old_txt_path = f\"{night_filenames[i][:-20]}/labels/{night_filenames[i][-12:-4]}.txt\"\n",
    "    with open(old_txt_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Split the line by the first space and take the first part\n",
    "            this_class = int(line.split(' ')[0])\n",
    "            this_dataset_classes.add(this_class)\n",
    "\n",
    "# Creating conversion between all possible classes and classes for this dataset\n",
    "this_dataset_classes = sorted(list(this_dataset_classes))\n",
    "# print(this_dataset_classes)\n",
    "conversion_dict = {}\n",
    "this_dataset_dict = {}\n",
    "for i in range(len(this_dataset_classes)):\n",
    "    conversion_dict[this_dataset_classes[i]] = i\n",
    "    this_dataset_dict[conversion_dict[this_dataset_classes[i]]] = unique_dict[this_dataset_classes[i]]\n",
    "    # print(this_dataset_dict)\n",
    "# The result: conversion_dict is used to convert from the classNum in the txt files into the classNum corresponding to the final YAML file\n",
    "# The result: this_dataset_dict is essentially the key to be used in the final yaml file\n",
    "    \n",
    "# Creating this YAML file\n",
    "dataset_name = dest_dir1.split('/')[-1]\n",
    "write_yaml_config(\n",
    "    this_dataset_dict, \n",
    "    # {0: 'traffic light'},\n",
    "    f'./{dataset_name}.yaml',\n",
    "    primary_path=f'/home/letucker/road_asset_images/YOLO_data/{dataset_name}',\n",
    "    train_path='train/',\n",
    "    test_path='test/',\n",
    "    valid_path='valid/',\n",
    ")\n",
    "\n",
    "# Copying files into new dataset\n",
    "day_range_boundaries = [(\"day\", \"train\", 0, dataset_size * day_proportion * train_proportion),\n",
    "                        (\"day\", \"valid\", dataset_size * day_proportion * train_proportion, dataset_size * day_proportion * (train_proportion + val_proportion)),\n",
    "                        (\"day\", \"test\", dataset_size * day_proportion * (train_proportion + val_proportion), dataset_size * day_proportion * (train_proportion + val_proportion + test_proportion))]\n",
    "night_range_boundaries = [(\"night\", \"train\", 0, dataset_size * night_proportion * train_proportion),\n",
    "                          (\"night\", \"valid\", dataset_size * night_proportion * train_proportion, dataset_size * night_proportion * (train_proportion + val_proportion)),\n",
    "                          (\"night\", \"test\", dataset_size * night_proportion * (train_proportion + val_proportion), dataset_size * night_proportion * (train_proportion + val_proportion + test_proportion))]\n",
    "\n",
    "second_lookup_dict = {}\n",
    "\n",
    "# Copying all day files into new dataset\n",
    "for t in day_range_boundaries:\n",
    "    for i in range(int(t[2]), int(t[3])):\n",
    "        # Copying image to new location\n",
    "        old_img_path = day_filenames[i]\n",
    "        new_img_path = f\"{dest_dir1}/{t[1]}/images/{t[0]}_{i+1}.jpg\"\n",
    "        shutil.copy(old_img_path, new_img_path)\n",
    "    \n",
    "        old_txt_path = f\"{day_filenames[i][:-20]}/labels/{day_filenames[i][-12:-4]}.txt\"\n",
    "        # print(day_filenames[i][-12:-4], day_filenames[i])\n",
    "        new_txt_path = f\"{dest_dir1}/{t[1]}/labels/{t[0]}_{i+1}.txt\"\n",
    "\n",
    "        # Reading text from old file\n",
    "        with open(old_txt_path, 'r') as file:\n",
    "            lines = []\n",
    "            for line in file:\n",
    "                # Split the line by the first space and take the first part\n",
    "                this_class = int(line.split(' ')[0])\n",
    "                lines.append(f\"{conversion_dict[int(line.split(' ')[0])]} {' '.join(line.split(' ')[1:])}\")\n",
    "                # lines.append(f\"0 {' '.join(line.split(' ')[1:])}\") # For one-class training\n",
    "                # print(' '.join(line.split(' ')[1]))\n",
    "                # print(line)\n",
    "            this_file_text = \"\\n\".join(lines)\n",
    "\n",
    "        # Writing text to new file\n",
    "        with open(new_txt_path, 'w') as file:\n",
    "            file.write(this_file_text)\n",
    "\n",
    "        second_lookup_dict[new_txt_path] = old_txt_path\n",
    "\n",
    "# Copying all night files into new dataset\n",
    "for t in night_range_boundaries:\n",
    "    for i in range(int(t[2]), int(t[3])):\n",
    "        # Copying image to new location\n",
    "        old_img_path = night_filenames[i]\n",
    "        new_img_path = f\"{dest_dir1}/{t[1]}/images/{t[0]}_{i+1}.jpg\"\n",
    "        shutil.copy(old_img_path, new_img_path)\n",
    "    \n",
    "        old_txt_path = f\"{night_filenames[i][:-20]}/labels/{night_filenames[i][-12:-4]}.txt\"\n",
    "        new_txt_path = f\"{dest_dir1}/{t[1]}/labels/{t[0]}_{i+1}.txt\"\n",
    "\n",
    "        # Reading text from old file\n",
    "        with open(old_txt_path, 'r') as file:\n",
    "            lines = []\n",
    "            for line in file:\n",
    "                # Split the line by the first space and take the first part\n",
    "                this_class = int(line.split(' ')[0])\n",
    "                lines.append(f\"{conversion_dict[int(line.split(' ')[0])]} {' '.join(line.split(' ')[1:])}\")\n",
    "                # lines.append(f\"0 {' '.join(line.split(' ')[1:])}\") # For one-class training\n",
    "            this_file_text = \"\\n\".join(lines)\n",
    "\n",
    "        # Writing text to new file\n",
    "        with open(new_txt_path, 'w') as file:\n",
    "            file.write(this_file_text)\n",
    "\n",
    "        second_lookup_dict[new_txt_path] = old_txt_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
